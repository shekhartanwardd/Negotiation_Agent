{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dc04029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b78784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1v/9s98_m5j64d4q08nsk639pmr0000gn/T/ipykernel_40728/1667955303.py:5: DtypeWarning: Columns (48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(path).iloc[:,1:]\n",
      "/var/folders/1v/9s98_m5j64d4q08nsk639pmr0000gn/T/ipykernel_40728/1667955303.py:5: DtypeWarning: Columns (23,24,25,37,38,52,53,54,55,56,57,58,186) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(path).iloc[:,1:]\n",
      "/var/folders/1v/9s98_m5j64d4q08nsk639pmr0000gn/T/ipykernel_40728/1667955303.py:5: DtypeWarning: Columns (24,25,26,38,39,53,54,55,56,57,58,59,187) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(path).iloc[:,1:]\n"
     ]
    }
   ],
   "source": [
    "# merge the two datasets, then focus on the column same as dataset_predictions, and also have\n",
    "# CONVERSATION column, then create a CONVERSATION_HUMAN_AGENT column\n",
    "\n",
    "def load_data(path):\n",
    "    return pd.read_csv(path).iloc[:,1:]\n",
    "\n",
    "# prediction dataset where feaures are log scaled\n",
    "path_predictions = '/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/processed_dataset/dataset_predictions.csv'\n",
    "dataset_predictions = load_data(path = path_predictions)\n",
    "dataset_predictions['DELIVERY_ID'] = dataset_predictions['DELIVERY_ID'].astype(np.float64)\n",
    "\n",
    "# dataset containing conversation and parsed_ac\n",
    "\n",
    "path_original = '/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/processed_dataset/dataset.csv'\n",
    "dataset_original = load_data(path = path_original)\n",
    "dataset_original['DELIVERY_ID'] = dataset_original['DELIVERY_ID'].astype(np.float64)\n",
    "dataset_original_filtered = dataset_original[['DELIVERY_ID', 'CONVERSATION','Parsed_AC','CONVERSATION_HUMAN_AGENT']]\n",
    "\n",
    "# exactly same as predictions dataset but features are not log scaled\n",
    "\n",
    "path_non_log = '/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/processed_dataset/dataset_non_log.csv'\n",
    "dataset_non_log = load_data(path_non_log)\n",
    "\n",
    "dataset_predictions_filtetred = dataset_predictions[['DELIVERY_ID','PREDICTED_ESCALATION_PROB','PREDICTED_ESCALATION']]\n",
    "dataset_original_filtered = dataset_original[['DELIVERY_ID', 'CONVERSATION', 'Parsed_AC', 'CONVERSATION_HUMAN_AGENT']]\n",
    "dataset_non_log_filtered = dataset_non_log[['DELIVERY_ID', 'ML_CX_CNR_RISK_V1_SCORE', 'SUBTOTAL', 'IS_ELITE_CX', 'CREDIT_REFUND_ORDER_COUNT_L28D', 'CREDIT_REFUND_ORDER_COUNT_L12M', 'SH_CNR']]\n",
    "\n",
    "# dataset containing all features\n",
    "\n",
    "temp1 = pd.merge(dataset_non_log_filtered, dataset_original_filtered, how = 'inner', left_on = 'DELIVERY_ID', right_on = 'DELIVERY_ID')\n",
    "dataset = pd.merge(temp1, dataset_predictions_filtetred, how = 'inner', left_on = 'DELIVERY_ID', right_on = 'DELIVERY_ID')\n",
    "dataset.columns = ['DELIVERY_ID', 'IS_CNR_ABUSER', 'ORDER_SUBTOTAL', 'IS_VIP_CUSTOMER', 'ISSUE_COUNT_LAST_10_ORDERS', 'ISSUE_COUNT_LAST_10_DAYS', 'SH_CNR', 'CONVERSATION', 'Parsed_AC', 'CONVERSATION_HUMAN_AGENT', 'PREDICTED_ESCALATION_PROB', 'PREDICTED_ESCALATION']\n",
    "dataset = dataset[[\n",
    "\n",
    "    'DELIVERY_ID', \n",
    "    'CONVERSATION',\n",
    "    'IS_CNR_ABUSER',\n",
    "    'Parsed_AC',\n",
    "    'ORDER_SUBTOTAL',\n",
    "    'IS_VIP_CUSTOMER',\n",
    "    'ISSUE_COUNT_LAST_10_ORDERS',\n",
    "    'ISSUE_COUNT_LAST_10_DAYS',\n",
    "    'PREDICTED_ESCALATION_PROB',\n",
    "    'SH_CNR'\n",
    "\n",
    "]]\n",
    "\n",
    "\n",
    "FEATURE_MAPPING = {\n",
    "    \"CONVERSATION_CB\": [\"CONVERSATION_CB\", \"CONVERSATION\"],\n",
    "    \"IS_CNR_ABUSER\": [\"ML_CX_CNR_RISK_V1_SCORE\"],  # Using the available alias\n",
    "    \"Parsed_AC\": [\"Parsed_AC\"],\n",
    "    \"ORDER_SUBTOTAL\": [\"SUBTOTAL\"],  # Using the available alias\n",
    "    \"IS_VIP_CUSTOMER\": [\"IS_ELITE_CX\"],  # Using IS_ELITE_CX as VIP proxy (available in dataset)\n",
    "    \"ISSUE_COUNT_LAST_10_ORDERS\": [\"CREDIT_REFUND_ORDER_COUNT_L28D\"],\n",
    "    \"ISSUE_COUNT_LAST_10_DAYS\": [\"CREDIT_REFUND_ORDER_COUNT_L12M\"],\n",
    "    \"PREDICTED_ESCALATION_PROB\": [\"PREDICTED_ESCALATION_PROB\"],\n",
    "    \"SH_CNR\": [\"SH_CNR\"],\n",
    "    \"DELIVERY_ID\": [\"DELIVERY_ID\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209cc75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_predictions, dataset_original, dataset_non_log, dataset_predictions_filtetred, dataset_non_log_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1cab53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IS_ELITE_CX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IS_ELITE_CX\n",
       "0          0.0\n",
       "1          0.0\n",
       "2          0.0\n",
       "3          0.0\n",
       "4          0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_non_log[['IS_ELITE_CX']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8af4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc1aaba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.reset_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86429959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DELIVERY_ID</th>\n",
       "      <th>CONVERSATION</th>\n",
       "      <th>IS_CNR_ABUSER</th>\n",
       "      <th>Parsed_AC</th>\n",
       "      <th>ORDER_SUBTOTAL</th>\n",
       "      <th>IS_VIP_CUSTOMER</th>\n",
       "      <th>ISSUE_COUNT_LAST_10_ORDERS</th>\n",
       "      <th>ISSUE_COUNT_LAST_10_DAYS</th>\n",
       "      <th>PREDICTED_ESCALATION_PROB</th>\n",
       "      <th>SH_CNR</th>\n",
       "      <th>CONVERSATION_HUMAN_AGENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.179857e+11</td>\n",
       "      <td>Chatbot: Hi Deepak, I'm your DoorDash virtual ...</td>\n",
       "      <td>0.566943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3398.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102361</td>\n",
       "      <td>16.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.560231e+11</td>\n",
       "      <td>Chatbot: Hi aj, I'm your DoorDash virtual assi...</td>\n",
       "      <td>0.915407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.621826e+11</td>\n",
       "      <td>Chatbot: Hi Luke, I'm your DoorDash virtual as...</td>\n",
       "      <td>0.099998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.349462</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.768723e+11</td>\n",
       "      <td>Chatbot: Hi Colin, I'm your DoorDash virtual a...</td>\n",
       "      <td>0.014588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.198509</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.184242e+11</td>\n",
       "      <td>Chatbot: Hi Cassandra, I'm your DoorDash virtu...</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185310</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DELIVERY_ID                                       CONVERSATION  \\\n",
       "0  2.179857e+11  Chatbot: Hi Deepak, I'm your DoorDash virtual ...   \n",
       "1  3.560231e+11  Chatbot: Hi aj, I'm your DoorDash virtual assi...   \n",
       "2  2.621826e+11  Chatbot: Hi Luke, I'm your DoorDash virtual as...   \n",
       "3  2.768723e+11  Chatbot: Hi Colin, I'm your DoorDash virtual a...   \n",
       "4  3.184242e+11  Chatbot: Hi Cassandra, I'm your DoorDash virtu...   \n",
       "\n",
       "   IS_CNR_ABUSER  Parsed_AC  ORDER_SUBTOTAL  IS_VIP_CUSTOMER  \\\n",
       "0       0.566943        0.0          3398.0              0.0   \n",
       "1       0.915407        0.0             0.0              0.0   \n",
       "2       0.099998        0.0          3900.0              0.0   \n",
       "3       0.014588        0.0          1516.0              0.0   \n",
       "4       0.240459        0.0          2800.0              0.0   \n",
       "\n",
       "   ISSUE_COUNT_LAST_10_ORDERS  ISSUE_COUNT_LAST_10_DAYS  \\\n",
       "0                         0.0                       1.0   \n",
       "1                         0.0                       4.0   \n",
       "2                         0.0                      15.0   \n",
       "3                         1.0                       1.0   \n",
       "4                         0.0                       0.0   \n",
       "\n",
       "   PREDICTED_ESCALATION_PROB  SH_CNR  CONVERSATION_HUMAN_AGENT  \n",
       "0                   0.102361   16.88                         1  \n",
       "1                   0.008399   -1.00                         1  \n",
       "2                   0.349462   -1.00                         1  \n",
       "3                   0.198509   -1.00                         1  \n",
       "4                   0.185310   -1.00                         1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef26d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_conversation_before_agent_transfer(conversation):\n",
    "    \"\"\"\n",
    "    Parse the CONVERSATION column and filter to keep only the chatbot conversation\n",
    "    portion - everything before the customer asks for a human agent.\n",
    "    \n",
    "    The function looks for the \"System: Connecting you with an agent...\" message\n",
    "    and returns everything before that point.\n",
    "    \n",
    "    Args:\n",
    "        conversation: String containing the full conversation\n",
    "        \n",
    "    Returns:\n",
    "        str: Parsed conversation up to (but not including) the agent transfer message\n",
    "             Returns the original conversation if no transfer message is found\n",
    "             Returns empty string if conversation is None/NaN\n",
    "    \"\"\"\n",
    "    # Handle None or NaN values\n",
    "    if pd.isna(conversation) or conversation is None:\n",
    "        return \"\"\n",
    "    \n",
    "    conversation = str(conversation)\n",
    "    \n",
    "    # Pattern to match the system message indicating agent transfer\n",
    "    # This captures the point where the customer is being connected to an agent\n",
    "    transfer_patterns = [\n",
    "        r\"System:\\s*Connecting you with an agent\\.*\",\n",
    "        r\"System:\\s*You are now connected to our support agent\",\n",
    "        r\"System:\\s*Transferring you to an agent\",\n",
    "    ]\n",
    "    \n",
    "    # Find the earliest occurrence of any transfer pattern\n",
    "    earliest_pos = len(conversation)\n",
    "    for pattern in transfer_patterns:\n",
    "        match = re.search(pattern, conversation, re.IGNORECASE)\n",
    "        if match:\n",
    "            earliest_pos = min(earliest_pos, match.start())\n",
    "    \n",
    "    # If no transfer message found, return the full conversation\n",
    "    if earliest_pos == len(conversation):\n",
    "        return conversation.strip()\n",
    "    \n",
    "    # Return everything before the transfer message\n",
    "    parsed = conversation[:earliest_pos].strip()\n",
    "    \n",
    "    return parsed\n",
    "\n",
    "\n",
    "def add_conversation_cb_column(df, conversation_col='CONVERSATION', new_col='CONVERSATION_CB'):\n",
    "    \"\"\"\n",
    "    Add a new column with parsed conversations (chatbot portion only).\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the conversation column\n",
    "        conversation_col: Name of the conversation column\n",
    "        new_col: Name of the new column to create\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the new column added\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(f\"Parsing {len(df):,} conversations...\")\n",
    "    \n",
    "    # Apply the parsing function\n",
    "    df[new_col] = df[conversation_col].apply(parse_conversation_before_agent_transfer)\n",
    "    \n",
    "    # Calculate stats\n",
    "    non_empty = (df[new_col].str.len() > 0).sum()\n",
    "    truncated = (df[new_col].str.len() < df[conversation_col].fillna('').str.len()).sum()\n",
    "    \n",
    "    print(f\"✓ Created column '{new_col}'\")\n",
    "    print(f\"  - Non-empty conversations: {non_empty:,}\")\n",
    "    print(f\"  - Conversations truncated (had agent transfer): {truncated:,}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "human_agent_cases = []\n",
    "for conversation in list(dataset['CONVERSATION']):\n",
    "    if 'Human Agent' in conversation:\n",
    "        human_agent_cases.append(1)\n",
    "    else:\n",
    "        human_agent_cases.append(0)\n",
    "dataset['CONVERSATION_HUMAN_AGENT'] = human_agent_cases \n",
    "# Example usage - show before/after for a sample conversation\n",
    "sample_idx = dataset[dataset['CONVERSATION_HUMAN_AGENT'] == 1].index[1]\n",
    "sample_conv = dataset.loc[sample_idx, 'CONVERSATION']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAMPLE CONVERSATION - BEFORE PARSING:\")\n",
    "print(\"=\" * 60)\n",
    "print(sample_conv[:1500] if len(str(sample_conv)) > 1500 else sample_conv)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE CONVERSATION - AFTER PARSING (CHATBOT PORTION ONLY):\")\n",
    "print(\"=\" * 60)\n",
    "parsed_sample = parse_conversation_before_agent_transfer(sample_conv)\n",
    "print(parsed_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bc5a20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 1,414,041 conversations...\n",
      "✓ Created column 'CONVERSATION_CB'\n",
      "  - Non-empty conversations: 1,414,038\n",
      "  - Conversations truncated (had agent transfer): 747,406\n",
      "\n",
      "============================================================\n",
      "DATASET WITH NEW COLUMN:\n",
      "============================================================\n",
      "Dataset shape: (1414041, 202)\n",
      "\n",
      "Columns including CONVERSATION_CB:\n",
      "['CONVERSATION', 'ACTUAL_AC_CONVERSATION', 'CONVERSATION_HUMAN_AGENT', 'CONVERSATION_CB']\n"
     ]
    }
   ],
   "source": [
    "# Apply the parsing function to the entire dataset\n",
    "dataset_non_log = add_conversation_cb_column(dataset_non_log, conversation_col='CONVERSATION', new_col='CONVERSATION_CB')\n",
    "\n",
    "# Show the new column\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATASET WITH NEW COLUMN:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset shape: {dataset_non_log.shape}\")\n",
    "print(f\"\\nColumns including CONVERSATION_CB:\")\n",
    "conv_cols = [c for c in dataset_non_log.columns if 'CONVERSATION' in c]\n",
    "print(conv_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed272b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversations with agent transfer (truncated): 747,406\n",
      "Conversations without agent transfer: 666,635\n",
      "\n",
      "============================================================\n",
      "SAMPLE PARSED CHATBOT CONVERSATIONS (CONVERSATION_CB):\n",
      "============================================================\n",
      "\n",
      "--- Example 1 ---\n",
      "Original length: 2721 chars\n",
      "Parsed (CB) length: 1074 chars\n",
      "\n",
      "Parsed conversation (CONVERSATION_CB):\n",
      "Chatbot: Hi Deepak, I'm your DoorDash virtual assistant. Thank you for being a loyal DashPass member since 2025.  It looks like you've been compensated for this order.\n",
      "\n",
      "Chatbot: \n",
      "You can select one of the options below. If it's something else, please describe your issue.\n",
      "Customer: It's something else\n",
      "Chatbot: Please tell us about your issue\n",
      "Customer: bad food quality and undercooked food, need full refund \n",
      "Chatbot: I’m sorry to hear the food quality wasn’t up to par. Just to confirm—you’re reporting bad food quality and undercooked food for this order, right?\n",
      "Customer: yes\n",
      "Chatbot: Could you please share a photo of the undercooked or poor-quality dish so I can look into this further?\n",
      "Chatbot: After looking into your order, it turns out it already received compensation, so I’m not able to i\n",
      "...\n",
      "\n",
      "--- Example 2 ---\n",
      "Original length: 2928 chars\n",
      "Parsed (CB) length: 1194 chars\n",
      "\n",
      "Parsed conversation (CONVERSATION_CB):\n",
      "Chatbot: Hi aj, I'm your DoorDash virtual assistant. \n",
      "Chatbot: \n",
      "You can select one of the options below. If it's something else, please describe your issue.\n",
      "Customer: help\n",
      "Chatbot: I can definitely connect you with an agent. Before I transfer you, can you share what's going on to see if I can help?\n",
      "Customer: don’t have my order \n",
      "Chatbot: I'm sorry to hear that you haven't received your order. Since your order is set for pickup, you'll need to contact KFC directly for updates.\n",
      "Chatbot: You can reach them at +19785670646. Please note that Dashers are not responsible for delivering pickup orders.\n",
      "Customer: I’m very frustrated. My order says ready and I’ve been  waiting but apparently, they’ve mixed up my order and asked me to wait another 15-20 min for them to fix it but i cannot wait. I have\n",
      "...\n",
      "\n",
      "--- Example 3 ---\n",
      "Original length: 1966 chars\n",
      "Parsed (CB) length: 411 chars\n",
      "\n",
      "Parsed conversation (CONVERSATION_CB):\n",
      "Chatbot: Hi Luke, I'm your DoorDash virtual assistant. Thank you for being a loyal DashPass member since 2023. Let me know how I can help you. \n",
      "Chatbot: \n",
      "You can select one of the options below. If it's something else, please describe your issue.\n",
      "Customer: Agent\n",
      "Chatbot: I see you want to connect with an agent. Could you please provide more details about your issue so I can assist you better?\n",
      "Customer: Agent\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify the parsing worked correctly - compare lengths\n",
    "dataset_non_log['CONV_ORIGINAL_LEN'] = dataset_non_log['CONVERSATION'].fillna('').str.len()\n",
    "dataset_non_log['CONV_CB_LEN'] = dataset_non_log['CONVERSATION_CB'].str.len()\n",
    "\n",
    "# Show statistics for conversations that were truncated (had agent transfer)\n",
    "truncated_mask = dataset_non_log['CONV_CB_LEN'] < dataset_non_log['CONV_ORIGINAL_LEN']\n",
    "print(f\"Conversations with agent transfer (truncated): {truncated_mask.sum():,}\")\n",
    "print(f\"Conversations without agent transfer: {(~truncated_mask).sum():,}\")\n",
    "\n",
    "# Show a few examples of the parsed chatbot conversations\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE PARSED CHATBOT CONVERSATIONS (CONVERSATION_CB):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get samples from conversations that had agent transfers\n",
    "sample_indices = dataset_non_log[truncated_mask & (dataset_non_log['CONVERSATION_HUMAN_AGENT'] == 1)].head(3).index\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(f\"Original length: {dataset_non_log.loc[idx, 'CONV_ORIGINAL_LEN']} chars\")\n",
    "    print(f\"Parsed (CB) length: {dataset_non_log.loc[idx, 'CONV_CB_LEN']} chars\")\n",
    "    print(f\"\\nParsed conversation (CONVERSATION_CB):\")\n",
    "    print(dataset_non_log.loc[idx, 'CONVERSATION_CB'][:800])\n",
    "    print(\"...\" if len(dataset_non_log.loc[idx, 'CONVERSATION_CB']) > 800 else \"\")\n",
    "\n",
    "# Clean up temporary columns\n",
    "dataset_non_log.drop(columns=['CONV_ORIGINAL_LEN', 'CONV_CB_LEN'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf82f03",
   "metadata": {},
   "source": [
    "# Feature List Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac8a64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "all_features = pd.DataFrame(dataset.columns.tolist())\n",
    "all_features.columns = ['feature']\n",
    "#all_features.to_csv('/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/all_features/all_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2b3144",
   "metadata": {},
   "source": [
    "# Saving Dataset to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fec76f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/processed_dataset/final_dataset_negotiation_agent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17442f6d",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbafca51",
   "metadata": {},
   "source": [
    "# Expected Features By GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f39b1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': [{'name': 'CONVERSATION_CB',\n",
       "   'aliases': ['CONVERSATION_CB', 'CONVERSATION'],\n",
       "   'role': 'conversation_input',\n",
       "   'required_level': 'required',\n",
       "   'purpose': 'Primary conversation text (bot + customer) for inferring legal threats, reputation risk, refund dissatisfaction, special occasion impact, and agent escalation pressure.'},\n",
       "  {'name': 'IS_CNR_ABUSER',\n",
       "   'aliases': ['IS_CNR_ABUSER', 'ML_CX_CNR_RISK_V1_SCORE'],\n",
       "   'role': 'eligibility_gate',\n",
       "   'required_level': 'required',\n",
       "   'purpose': 'Hard gate for credit/refund abuse. If true/high → block apology credit issuance per policy.'},\n",
       "  {'name': 'Parsed_AC',\n",
       "   'aliases': ['Parsed_AC', 'APOLOGY_CREDIT_ISSUED', 'AC_AMOUNT'],\n",
       "   'role': 'eligibility_gate',\n",
       "   'required_level': 'required',\n",
       "   'purpose': 'Indicates whether an apology credit has already been granted for this case/order and its amount. Apology credit allowed only once.'},\n",
       "  {'name': 'ORDER_SUBTOTAL',\n",
       "   'aliases': ['ORDER_SUBTOTAL', 'SUBTOTAL'],\n",
       "   'role': 'order_value',\n",
       "   'required_level': 'required',\n",
       "   'purpose': 'Order subtotal (USD). Used to map to apology credit tiers (policy Step 6).'},\n",
       "  {'name': 'IS_VIP_CUSTOMER',\n",
       "   'aliases': ['IS_VIP_CUSTOMER', 'VIP_FLAG'],\n",
       "   'role': 'customer_flag',\n",
       "   'required_level': 'required',\n",
       "   'purpose': 'Determines whether VIP credit table applies (VIPs receive higher suggested amounts).'},\n",
       "  {'name': 'ISSUE_COUNT_LAST_10_ORDERS',\n",
       "   'aliases': ['ISSUE_COUNT_LAST_10_ORDERS',\n",
       "    'CREDIT_REFUND_ORDER_COUNT_L28D',\n",
       "    'ISSUE_COUNT_L10ORDERS'],\n",
       "   'role': 'customer_history',\n",
       "   'required_level': 'recommended',\n",
       "   'purpose': 'Count of orders with issues in the last 10 orders. Implements policy rule: 2+ issues in last 10 orders qualifies for apology credit consideration.'},\n",
       "  {'name': 'ISSUE_COUNT_LAST_10_DAYS',\n",
       "   'aliases': ['ISSUE_COUNT_LAST_10_DAYS',\n",
       "    'CREDIT_REFUND_ORDER_COUNT_L12M',\n",
       "    'ISSUE_COUNT_L10DAYS'],\n",
       "   'role': 'customer_history',\n",
       "   'required_level': 'recommended',\n",
       "   'purpose': 'Count of issues in the last 10 days. Policy uses 2+ issues in last 10 days as a trigger.'},\n",
       "  {'name': 'PREDICTED_ESCALATION_PROB',\n",
       "   'aliases': ['PREDICTED_ESCALATION_PROB', 'PREDICTED_ESCALATION'],\n",
       "   'role': 'escalation_risk',\n",
       "   'required_level': 'recommended',\n",
       "   'purpose': 'Modelled probability (or binary) of escalation to human / social media / regulatory action. Used as a tie-breaker to bias toward issuing conservative apology credit when risk is high.'},\n",
       "  {'name': 'SH_CNR',\n",
       "   'aliases': ['SH_CNR', 'TOTAL_CREDITS_REFUNDS_ISSUED'],\n",
       "   'role': 'compensation_context',\n",
       "   'required_level': 'recommended',\n",
       "   'purpose': \"Total credits/refunds already issued on the order—used to avoid over-compensating and to honor the 'apology credit only once' rule.\"},\n",
       "  {'name': 'DELIVERY_ID',\n",
       "   'aliases': ['DELIVERY_ID', 'ORDER_ID'],\n",
       "   'role': 'traceability',\n",
       "   'required_level': 'recommended',\n",
       "   'purpose': 'Order/delivery identifier for joins, record-keeping, and audit trails.'}]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"name\": \"CONVERSATION_CB\",\n",
    "      \"aliases\": [\"CONVERSATION_CB\", \"CONVERSATION\"],\n",
    "      \"role\": \"conversation_input\",\n",
    "      \"required_level\": \"required\",\n",
    "      \"purpose\": \"Primary conversation text (bot + customer) for inferring legal threats, reputation risk, refund dissatisfaction, special occasion impact, and agent escalation pressure.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"IS_CNR_ABUSER\",\n",
    "      \"aliases\": [\"IS_CNR_ABUSER\", \"ML_CX_CNR_RISK_V1_SCORE\"],\n",
    "      \"role\": \"eligibility_gate\",\n",
    "      \"required_level\": \"required\",\n",
    "      \"purpose\": \"Hard gate for credit/refund abuse. If true/high → block apology credit issuance per policy.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Parsed_AC\",\n",
    "      \"aliases\": [\"Parsed_AC\", \"APOLOGY_CREDIT_ISSUED\", \"AC_AMOUNT\"],\n",
    "      \"role\": \"eligibility_gate\",\n",
    "      \"required_level\": \"required\",\n",
    "      \"purpose\": \"Indicates whether an apology credit has already been granted for this case/order and its amount. Apology credit allowed only once.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ORDER_SUBTOTAL\",\n",
    "      \"aliases\": [\"ORDER_SUBTOTAL\", \"SUBTOTAL\"],\n",
    "      \"role\": \"order_value\",\n",
    "      \"required_level\": \"required\",\n",
    "      \"purpose\": \"Order subtotal (USD). Used to map to apology credit tiers (policy Step 6).\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"IS_VIP_CUSTOMER\",\n",
    "      \"aliases\": [\"IS_VIP_CUSTOMER\", \"VIP_FLAG\"],\n",
    "      \"role\": \"customer_flag\",\n",
    "      \"required_level\": \"required\",\n",
    "      \"purpose\": \"Determines whether VIP credit table applies (VIPs receive higher suggested amounts).\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ISSUE_COUNT_LAST_10_ORDERS\",\n",
    "      \"aliases\": [\"ISSUE_COUNT_LAST_10_ORDERS\", \"CREDIT_REFUND_ORDER_COUNT_L28D\", \"ISSUE_COUNT_L10ORDERS\"],\n",
    "      \"role\": \"customer_history\",\n",
    "      \"required_level\": \"recommended\",\n",
    "      \"purpose\": \"Count of orders with issues in the last 10 orders. Implements policy rule: 2+ issues in last 10 orders qualifies for apology credit consideration.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ISSUE_COUNT_LAST_10_DAYS\",\n",
    "      \"aliases\": [\"ISSUE_COUNT_LAST_10_DAYS\", \"CREDIT_REFUND_ORDER_COUNT_L12M\", \"ISSUE_COUNT_L10DAYS\"],\n",
    "      \"role\": \"customer_history\",\n",
    "      \"required_level\": \"recommended\",\n",
    "      \"purpose\": \"Count of issues in the last 10 days. Policy uses 2+ issues in last 10 days as a trigger.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"PREDICTED_ESCALATION_PROB\",\n",
    "      \"aliases\": [\"PREDICTED_ESCALATION_PROB\", \"PREDICTED_ESCALATION\"],\n",
    "      \"role\": \"escalation_risk\",\n",
    "      \"required_level\": \"recommended\",\n",
    "      \"purpose\": \"Modelled probability (or binary) of escalation to human / social media / regulatory action. Used as a tie-breaker to bias toward issuing conservative apology credit when risk is high.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"SH_CNR\",\n",
    "      \"aliases\": [\"SH_CNR\", \"TOTAL_CREDITS_REFUNDS_ISSUED\"],\n",
    "      \"role\": \"compensation_context\",\n",
    "      \"required_level\": \"recommended\",\n",
    "      \"purpose\": \"Total credits/refunds already issued on the order—used to avoid over-compensating and to honor the 'apology credit only once' rule.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"DELIVERY_ID\",\n",
    "      \"aliases\": [\"DELIVERY_ID\", \"ORDER_ID\"],\n",
    "      \"role\": \"traceability\",\n",
    "      \"required_level\": \"recommended\",\n",
    "      \"purpose\": \"Order/delivery identifier for joins, record-keeping, and audit trails.\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98879507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_conversation_filtered = dataset[dataset['Parsed_AC'] != 0][['DELIVERY_ID','CONVERSATION_CB','Parsed_AC']]\n",
    "# dataset_conversation_filtered = dataset_conversation_filtered.reset_index().iloc[:,1:]\n",
    "# dataset_conversation_filtered.to_csv('/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/processed_dataset/dataset_conversation_filtered.csv')\n",
    "# dataset_conversation_filtered['Conversation_length'] = dataset_conversation_filtered['CONVERSATION_CB'].apply(lambda x : len(x.split(' ')))\n",
    "# dataset_conversation_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ded5205",
   "metadata": {},
   "source": [
    "# Escalated Cases Payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eeab5550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total escalated cases: 51,540\n",
      "✓ Saved 51,540 escalated case payloads to:\n",
      "  /Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/escalated_payload/escalated_cases_payload.json\n",
      "\n",
      "============================================================\n",
      "SAMPLE PAYLOAD (first escalated case):\n",
      "============================================================\n",
      "{\n",
      "  \"CONVERSATION_CB\": \"Chatbot: Hi Shamso, I'm your DoorDash virtual assistant. Thank you for being one of our most loyal customers! Let me know how I can help you.\\n\\nChatbot: \\nYou can select one of the options below. If it's something else, please describe your issue\\nCustomer: I want too change my order\\nChatbot: Since your order is already being prepared, we are unable to make any changes. We apologize for the inconvenience.\\nCustomer: I clicked on the wrong item \\nChatbot: To help provide the right next steps, please let us know why you want to cancel your order. \\nCustomer: Order needs to be modified \\nChatbot: The store has started preparing this order so we can only refund the delivery charges and Dasher tip.\\n\\nChatbot: \\nYour total refund will be $4.00.\\n\\nChatbot: \\nHow would you like to proceed?\\nCustomer: Don't cancel\\nChatbot: Got it, we won't cancel your order.\\n\\nChatbot: \\nYour order should arrive at 6:29 PM.\\nCustomer: Please I need too modify my order\\nChatbot: I see you want to modify your order. To make changes, please connect with a live agent who can assist you further. Would you like me to connect you now?\\nCustomer: Yes\\nChatbot: Got it, let me connect you with a live agent who can help you with this.\\nSystem: Connecting you with an agent...\\nSystem: You are now connected to our support agent Ashish\\nHuman Agent: Hi Shamso, thank you for being one of DoorDash's most loyal customers!\\n\\n\\nCustomer: Hi I needed to modify my order because I clicked on the wrong item \\nHuman Agent: I understand that you want to modify  your order, let me check for the order details and help you with this. \\nCustomer: Ok \\nHuman Agent: Meanwhile, can you please let me know, what would you like to change in the order?\\nCustomer: The sprinkle box \\nHuman Agent: Ok, do you like to remove this item or want something else to add?\\nCustomer: Yes I want too change it too the Shipley box please\\nCustomer: Remove and add Shipley box \\nCustomer: Half dozen \\nHuman Agent:\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Feature mapping from the schema - maps our dataset columns to the required feature names\n",
    "# NOTE: The dataset columns have already been renamed in Cell 1, so we use the renamed column names as primary aliases\n",
    "FEATURE_MAPPING = {\n",
    "    \"CONVERSATION_CB\": [\"CONVERSATION_CB\", \"CONVERSATION\"],\n",
    "    \"IS_CNR_ABUSER\": [\"IS_CNR_ABUSER\", \"ML_CX_CNR_RISK_V1_SCORE\"],  # Column already renamed to IS_CNR_ABUSER\n",
    "    \"Parsed_AC\": [\"Parsed_AC\"],\n",
    "    \"ORDER_SUBTOTAL\": [\"ORDER_SUBTOTAL\", \"SUBTOTAL\"],  # Column already renamed to ORDER_SUBTOTAL\n",
    "    \"IS_VIP_CUSTOMER\": [\"IS_VIP_CUSTOMER\", \"IS_ELITE_CX\"],  # Column already renamed to IS_VIP_CUSTOMER\n",
    "    \"ISSUE_COUNT_LAST_10_ORDERS\": [\"ISSUE_COUNT_LAST_10_ORDERS\", \"CREDIT_REFUND_ORDER_COUNT_L28D\"],  # Column already renamed\n",
    "    \"ISSUE_COUNT_LAST_10_DAYS\": [\"ISSUE_COUNT_LAST_10_DAYS\", \"CREDIT_REFUND_ORDER_COUNT_L12M\"],  # Column already renamed\n",
    "    \"PREDICTED_ESCALATION_PROB\": [\"PREDICTED_ESCALATION_PROB\"],\n",
    "    \"SH_CNR\": [\"SH_CNR\"],\n",
    "    \"DELIVERY_ID\": [\"DELIVERY_ID\"]\n",
    "}\n",
    "\n",
    "def get_feature_value(row, feature_name, aliases):\n",
    "    \"\"\"\n",
    "    Get the value for a feature, trying aliases in order.\n",
    "    \"\"\"\n",
    "    for alias in aliases:\n",
    "        if alias in row.index and pd.notna(row[alias]):\n",
    "            return row[alias]\n",
    "    return None\n",
    "\n",
    "def create_escalated_payload(df):\n",
    "    \"\"\"\n",
    "    Create JSON payloads for escalated cases using the defined feature schema.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with escalated cases\n",
    "        \n",
    "    Returns:\n",
    "        list: List of JSON payload dictionaries\n",
    "    \"\"\"\n",
    "    payloads = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        payload = {}\n",
    "        \n",
    "        for feature_name, aliases in FEATURE_MAPPING.items():\n",
    "            value = get_feature_value(row, feature_name, aliases)\n",
    "            \n",
    "            # Handle specific type conversions\n",
    "            if value is not None:\n",
    "                # Convert numpy types to Python native types for JSON serialization\n",
    "                if hasattr(value, 'item'):\n",
    "                    value = value.item()\n",
    "                # Ensure floats are properly formatted\n",
    "                if isinstance(value, float):\n",
    "                    if value != value:  # NaN check\n",
    "                        value = None\n",
    "                    elif value == float('inf') or value == float('-inf'):\n",
    "                        value = None\n",
    "            \n",
    "            payload[feature_name] = value\n",
    "        \n",
    "        payloads.append(payload)\n",
    "    \n",
    "    return payloads\n",
    "\n",
    "\n",
    "# Filter dataset for cases with non zero apology credit\n",
    "escalated_df = dataset[dataset['Parsed_AC'] != 0].copy()\n",
    "print(f\"Total escalated cases: {len(escalated_df):,}\")\n",
    "\n",
    "# Create payloads\n",
    "payloads = create_escalated_payload(escalated_df)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = '/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/escalated_payload'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save to JSON file\n",
    "output_path = os.path.join(output_dir, 'escalated_cases_payload.json')\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(payloads, f, indent=2, default=str)\n",
    "\n",
    "print(f\"✓ Saved {len(payloads):,} escalated case payloads to:\")\n",
    "print(f\"  {output_path}\")\n",
    "\n",
    "# Show sample payload\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE PAYLOAD (first escalated case):\")\n",
    "print(\"=\" * 60)\n",
    "print(json.dumps(payloads[0], indent=2, default=str)[:2000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3961a36",
   "metadata": {},
   "source": [
    "# Non Escalated Cases Payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "677c49c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total escalated cases: 1,362,501\n",
      "✓ Saved 1,362,501 escalated case payloads to:\n",
      "  /Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/non_escalated_payload/non_escalated_cases_payload.json\n",
      "\n",
      "============================================================\n",
      "SAMPLE PAYLOAD (first escalated case):\n",
      "============================================================\n",
      "{\n",
      "  \"CONVERSATION_CB\": \"Chatbot: Hi Deepak, I'm your DoorDash virtual assistant. Thank you for being a loyal DashPass member since 2025.  It looks like you've been compensated for this order.\\n\\nChatbot: \\nYou can select one of the options below. If it's something else, please describe your issue.\\nCustomer: It's something else\\nChatbot: Please tell us about your issue\\nCustomer: bad food quality and undercooked food, need full refund \\nChatbot: I\\u2019m sorry to hear the food quality wasn\\u2019t up to par. Just to confirm\\u2014you\\u2019re reporting bad food quality and undercooked food for this order, right?\\nCustomer: yes\\nChatbot: Could you please share a photo of the undercooked or poor-quality dish so I can look into this further?\\nChatbot: After looking into your order, it turns out it already received compensation, so I\\u2019m not able to issue another refund. You can view the previous adjustment in your DoorDash order history. Let me know if there\\u2019s anything else I can help with.\\nCustomer: expect full refund \\nChatbot: I\\u2019ve escalated your request to a specialist who\\u2019ll review this and follow up with you soon.\\nSystem: Connecting you with an agent...\\nSystem: You are now connected to our support agent Nitin\\nCustomer: thanks\\nHuman Agent: Hi Deepak, thank you for being a DashPass member!\\nHuman Agent: I can imagine how frustrating that is, especially when you were looking forward to your meal. Thank you for bringing this to our attention.\\nHuman Agent: Can you please tell me the name of item effected?\\nCustomer: both chicken items a d both undercooked \\nCustomer: foodtastes as if the chicken is not fresh as well\\nHuman Agent: I\\u2019m really sorry you\\u2019re experiencing this problem. I know how frustrating it must be. I am here to help you.\\nHuman Agent: I can either process $10.66\\n  credits which will be reflected instantly and you can use them on your next order or a refund which will take 3-7  business days to reflect back to your accoun\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Feature mapping from the schema - maps our dataset columns to the required feature names\n",
    "# NOTE: The dataset columns have already been renamed in Cell 1, so we use the renamed column names as primary aliases\n",
    "FEATURE_MAPPING = {\n",
    "    \"CONVERSATION_CB\": [\"CONVERSATION_CB\", \"CONVERSATION\"],\n",
    "    \"IS_CNR_ABUSER\": [\"IS_CNR_ABUSER\", \"ML_CX_CNR_RISK_V1_SCORE\"],  # Column already renamed to IS_CNR_ABUSER\n",
    "    \"Parsed_AC\": [\"Parsed_AC\"],\n",
    "    \"ORDER_SUBTOTAL\": [\"ORDER_SUBTOTAL\", \"SUBTOTAL\"],  # Column already renamed to ORDER_SUBTOTAL\n",
    "    \"IS_VIP_CUSTOMER\": [\"IS_VIP_CUSTOMER\", \"IS_ELITE_CX\"],  # Column already renamed to IS_VIP_CUSTOMER\n",
    "    \"ISSUE_COUNT_LAST_10_ORDERS\": [\"ISSUE_COUNT_LAST_10_ORDERS\", \"CREDIT_REFUND_ORDER_COUNT_L28D\"],  # Column already renamed\n",
    "    \"ISSUE_COUNT_LAST_10_DAYS\": [\"ISSUE_COUNT_LAST_10_DAYS\", \"CREDIT_REFUND_ORDER_COUNT_L12M\"],  # Column already renamed\n",
    "    \"PREDICTED_ESCALATION_PROB\": [\"PREDICTED_ESCALATION_PROB\"],\n",
    "    \"SH_CNR\": [\"SH_CNR\"],\n",
    "    \"DELIVERY_ID\": [\"DELIVERY_ID\"]\n",
    "}\n",
    "\n",
    "def get_feature_value(row, feature_name, aliases):\n",
    "    \"\"\"\n",
    "    Get the value for a feature, trying aliases in order.\n",
    "    \"\"\"\n",
    "    for alias in aliases:\n",
    "        if alias in row.index and pd.notna(row[alias]):\n",
    "            return row[alias]\n",
    "    return None\n",
    "\n",
    "def create_escalated_payload(df):\n",
    "    \"\"\"\n",
    "    Create JSON payloads for escalated cases using the defined feature schema.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with escalated cases\n",
    "        \n",
    "    Returns:\n",
    "        list: List of JSON payload dictionaries\n",
    "    \"\"\"\n",
    "    payloads = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        payload = {}\n",
    "        \n",
    "        for feature_name, aliases in FEATURE_MAPPING.items():\n",
    "            value = get_feature_value(row, feature_name, aliases)\n",
    "            \n",
    "            # Handle specific type conversions\n",
    "            if value is not None:\n",
    "                # Convert numpy types to Python native types for JSON serialization\n",
    "                if hasattr(value, 'item'):\n",
    "                    value = value.item()\n",
    "                # Ensure floats are properly formatted\n",
    "                if isinstance(value, float):\n",
    "                    if value != value:  # NaN check\n",
    "                        value = None\n",
    "                    elif value == float('inf') or value == float('-inf'):\n",
    "                        value = None\n",
    "            \n",
    "            payload[feature_name] = value\n",
    "        \n",
    "        payloads.append(payload)\n",
    "    \n",
    "    return payloads\n",
    "\n",
    "\n",
    "# Filter dataset for escalated cases\n",
    "non_escalated_df = dataset[dataset['Parsed_AC'] == 0].copy()\n",
    "print(f\"Total escalated cases: {len(non_escalated_df):,}\")\n",
    "\n",
    "# Create payloads\n",
    "payloads = create_escalated_payload(non_escalated_df)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = '/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/non_escalated_payload'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save to JSON file\n",
    "output_path = os.path.join(output_dir, 'non_escalated_cases_payload.json')\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(payloads, f, indent=2, default=str)\n",
    "\n",
    "print(f\"✓ Saved {len(payloads):,} escalated case payloads to:\")\n",
    "print(f\"  {output_path}\")\n",
    "\n",
    "# Show sample payload\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE PAYLOAD (first escalated case):\")\n",
    "print(\"=\" * 60)\n",
    "print(json.dumps(payloads[0], indent=2, default=str)[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88b4b869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DELIVERY_ID</th>\n",
       "      <th>CONVERSATION</th>\n",
       "      <th>IS_CNR_ABUSER</th>\n",
       "      <th>Parsed_AC</th>\n",
       "      <th>ORDER_SUBTOTAL</th>\n",
       "      <th>IS_VIP_CUSTOMER</th>\n",
       "      <th>ISSUE_COUNT_LAST_10_ORDERS</th>\n",
       "      <th>ISSUE_COUNT_LAST_10_DAYS</th>\n",
       "      <th>PREDICTED_ESCALATION_PROB</th>\n",
       "      <th>SH_CNR</th>\n",
       "      <th>CONVERSATION_HUMAN_AGENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.179857e+11</td>\n",
       "      <td>Chatbot: Hi Deepak, I'm your DoorDash virtual ...</td>\n",
       "      <td>0.566943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3398.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102361</td>\n",
       "      <td>16.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.560231e+11</td>\n",
       "      <td>Chatbot: Hi aj, I'm your DoorDash virtual assi...</td>\n",
       "      <td>0.915407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.621826e+11</td>\n",
       "      <td>Chatbot: Hi Luke, I'm your DoorDash virtual as...</td>\n",
       "      <td>0.099998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.349462</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.768723e+11</td>\n",
       "      <td>Chatbot: Hi Colin, I'm your DoorDash virtual a...</td>\n",
       "      <td>0.014588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.198509</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.184242e+11</td>\n",
       "      <td>Chatbot: Hi Cassandra, I'm your DoorDash virtu...</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185310</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   DELIVERY_ID  \\\n",
       "0           0  2.179857e+11   \n",
       "1           1  3.560231e+11   \n",
       "2           2  2.621826e+11   \n",
       "3           3  2.768723e+11   \n",
       "4           4  3.184242e+11   \n",
       "\n",
       "                                        CONVERSATION  IS_CNR_ABUSER  \\\n",
       "0  Chatbot: Hi Deepak, I'm your DoorDash virtual ...       0.566943   \n",
       "1  Chatbot: Hi aj, I'm your DoorDash virtual assi...       0.915407   \n",
       "2  Chatbot: Hi Luke, I'm your DoorDash virtual as...       0.099998   \n",
       "3  Chatbot: Hi Colin, I'm your DoorDash virtual a...       0.014588   \n",
       "4  Chatbot: Hi Cassandra, I'm your DoorDash virtu...       0.240459   \n",
       "\n",
       "   Parsed_AC  ORDER_SUBTOTAL  IS_VIP_CUSTOMER  ISSUE_COUNT_LAST_10_ORDERS  \\\n",
       "0        0.0          3398.0              0.0                         0.0   \n",
       "1        0.0             0.0              0.0                         0.0   \n",
       "2        0.0          3900.0              0.0                         0.0   \n",
       "3        0.0          1516.0              0.0                         1.0   \n",
       "4        0.0          2800.0              0.0                         0.0   \n",
       "\n",
       "   ISSUE_COUNT_LAST_10_DAYS  PREDICTED_ESCALATION_PROB  SH_CNR  \\\n",
       "0                       1.0                   0.102361   16.88   \n",
       "1                       4.0                   0.008399   -1.00   \n",
       "2                      15.0                   0.349462   -1.00   \n",
       "3                       1.0                   0.198509   -1.00   \n",
       "4                       0.0                   0.185310   -1.00   \n",
       "\n",
       "   CONVERSATION_HUMAN_AGENT  \n",
       "0                         1  \n",
       "1                         1  \n",
       "2                         1  \n",
       "3                         1  \n",
       "4                         1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/processed_dataset/final_dataset_negotiation_agent.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75e17e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DELIVERY_ID</th>\n",
       "      <th>CONVERSATION</th>\n",
       "      <th>IS_CNR_ABUSER</th>\n",
       "      <th>Parsed_AC</th>\n",
       "      <th>ORDER_SUBTOTAL</th>\n",
       "      <th>IS_VIP_CUSTOMER</th>\n",
       "      <th>ISSUE_COUNT_LAST_10_ORDERS</th>\n",
       "      <th>ISSUE_COUNT_LAST_10_DAYS</th>\n",
       "      <th>PREDICTED_ESCALATION_PROB</th>\n",
       "      <th>SH_CNR</th>\n",
       "      <th>CONVERSATION_HUMAN_AGENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1413672</th>\n",
       "      <td>1413672</td>\n",
       "      <td>2.941946e+11</td>\n",
       "      <td>Chatbot: Hi Alex, I'm your DoorDash virtual as...</td>\n",
       "      <td>0.242129</td>\n",
       "      <td>9.75</td>\n",
       "      <td>5195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.14669</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0   DELIVERY_ID  \\\n",
       "1413672     1413672  2.941946e+11   \n",
       "\n",
       "                                              CONVERSATION  IS_CNR_ABUSER  \\\n",
       "1413672  Chatbot: Hi Alex, I'm your DoorDash virtual as...       0.242129   \n",
       "\n",
       "         Parsed_AC  ORDER_SUBTOTAL  IS_VIP_CUSTOMER  \\\n",
       "1413672       9.75          5195.0              0.0   \n",
       "\n",
       "         ISSUE_COUNT_LAST_10_ORDERS  ISSUE_COUNT_LAST_10_DAYS  \\\n",
       "1413672                         0.0                       2.0   \n",
       "\n",
       "         PREDICTED_ESCALATION_PROB  SH_CNR  CONVERSATION_HUMAN_AGENT  \n",
       "1413672                    0.14669    -1.0                         1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset['DELIVERY_ID'] == 294194640240.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a78ff4",
   "metadata": {},
   "source": [
    "# Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "982bb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../scripts')\n",
    "\n",
    "# Step 2: Import functions\n",
    "from parse_apology_credits import (\n",
    "    process_dataframe,                          # All-in-one processing (recommended)\n",
    "    extract_conversation_cb,                    # Just extract chatbot portion\n",
    "    extract_apology_credits_from_dataframe,     # Just extract apology credits\n",
    "    extract_apology_credit,                     # Single conversation -> amount\n",
    "    parse_conversation_before_agent_transfer    # Single conversation -> CB text\n",
    ")\n",
    "\n",
    "\n",
    "dataset_final  = pd.read_csv('/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/processed_dataset/final_dataset_negotiation_agent.csv')\n",
    "#dataset_final['ORDER_SUBTOTAL'] = dataset_final['ORDER_SUBTOTAL'].apply(lambda x : x/100)\n",
    "#dataset_final = add_conversation_cb_column(dataset_final, conversation_col='CONVERSATION', new_col='CONVERSATION_CB')\n",
    "#dataset_final.to_csv('/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/processed_dataset/final_dataset_negotiation_agent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd9a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Processing DataFrame\n",
      "============================================================\n",
      "Parsing 1,414,041 conversations...\n",
      "✓ Created column 'CONVERSATION_CB'\n",
      "  - Non-empty conversations: 1,414,038\n",
      "  - Conversations truncated (had agent transfer): 747,406\n",
      "\n",
      "Extracting apology credits from 1,414,041 rows...\n",
      "✓ Added column 'Extracted_AC'\n",
      "  - Rows with extracted AC > 0: 56,126 (4.0%)\n",
      "  - Total extracted amount: $703,085.28\n",
      "  - Average (when > 0): $12.53\n",
      "\n",
      "============================================================\n",
      "✓ Processing complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "dataset_final = process_dataframe(\n",
    "    dataset_final,\n",
    "    conversation_col='CONVERSATION',    # Column with full conversation\n",
    "    extract_cb=True,                    # Add CONVERSATION_CB column\n",
    "    extract_ac=True,                    # Add Extracted_AC column\n",
    "    include_ac_details=False,           # Set True for match details\n",
    "    ac_from_full_conversation=True      # Extract AC from full conversation (includes human agent)\n",
    ")\n",
    "\n",
    "dataset_final['Final_AC'] = dataset_final[['Parsed_AC', 'Extracted_AC']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f5caa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_final.to_csv('/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/processed_dataset/final_dataset_negotiation_agent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b8725d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_lines = ''.join(list(dataset_final[dataset_final['DELIVERY_ID'] == 294194640240.0]['CONVERSATION'])).split('\\n')\n",
    "\n",
    "# for line in all_lines:\n",
    "#     if '$' in line:\n",
    "#         print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bb3e4c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final_AC Statistics:\n",
      "  - Records where Final_AC > 0: 67,506\n",
      "  - Total Final_AC amount: $848,851.66\n",
      "  - Records where Parsed_AC > Extracted_AC: 11,669\n",
      "  - Records where Extracted_AC > Parsed_AC: 17,394\n",
      "  - Records where both are equal (and > 0): 38,443\n"
     ]
    }
   ],
   "source": [
    "# Create Final_AC as the maximum of Parsed_AC and Extracted_AC\n",
    "# This ensures we capture the apology credit amount from whichever source has the higher value\n",
    "#dataset_final['Final_AC'] = dataset_final[['Parsed_AC', 'Extracted_AC']].max(axis=1)\n",
    "\n",
    "# Show statistics\n",
    "print(\"Final_AC Statistics:\")\n",
    "print(f\"  - Records where Final_AC > 0: {(dataset_final['Final_AC'] > 0).sum():,}\")\n",
    "print(f\"  - Total Final_AC amount: ${dataset_final['Final_AC'].sum():,.2f}\")\n",
    "print(f\"  - Records where Parsed_AC > Extracted_AC: {(dataset_final['Parsed_AC'] > dataset_final['Extracted_AC']).sum():,}\")\n",
    "print(f\"  - Records where Extracted_AC > Parsed_AC: {(dataset_final['Extracted_AC'] > dataset_final['Parsed_AC']).sum():,}\")\n",
    "print(f\"  - Records where both are equal (and > 0): {((dataset_final['Parsed_AC'] == dataset_final['Extracted_AC']) & (dataset_final['Final_AC'] > 0)).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "437c22e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13131, 16)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_final[dataset_final['PREDICTED_ESCALATION_PROB'] >= 0.5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "027e4a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DELIVERY_ID</th>\n",
       "      <th>CONVERSATION</th>\n",
       "      <th>IS_CNR_ABUSER</th>\n",
       "      <th>Parsed_AC</th>\n",
       "      <th>ORDER_SUBTOTAL</th>\n",
       "      <th>IS_VIP_CUSTOMER</th>\n",
       "      <th>ISSUE_COUNT_LAST_10_ORDERS</th>\n",
       "      <th>ISSUE_COUNT_LAST_10_DAYS</th>\n",
       "      <th>PREDICTED_ESCALATION_PROB</th>\n",
       "      <th>SH_CNR</th>\n",
       "      <th>CONVERSATION_HUMAN_AGENT</th>\n",
       "      <th>CONVERSATION_CB</th>\n",
       "      <th>Extracted_AC</th>\n",
       "      <th>Final_AC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.179857e+11</td>\n",
       "      <td>Chatbot: Hi Deepak, I'm your DoorDash virtual ...</td>\n",
       "      <td>0.566943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102361</td>\n",
       "      <td>16.88</td>\n",
       "      <td>1</td>\n",
       "      <td>Chatbot: Hi Deepak, I'm your DoorDash virtual ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.560231e+11</td>\n",
       "      <td>Chatbot: Hi aj, I'm your DoorDash virtual assi...</td>\n",
       "      <td>0.915407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Chatbot: Hi aj, I'm your DoorDash virtual assi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.621826e+11</td>\n",
       "      <td>Chatbot: Hi Luke, I'm your DoorDash virtual as...</td>\n",
       "      <td>0.099998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.349462</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Chatbot: Hi Luke, I'm your DoorDash virtual as...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.768723e+11</td>\n",
       "      <td>Chatbot: Hi Colin, I'm your DoorDash virtual a...</td>\n",
       "      <td>0.014588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.198509</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Chatbot: Hi Colin, I'm your DoorDash virtual a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.184242e+11</td>\n",
       "      <td>Chatbot: Hi Cassandra, I'm your DoorDash virtu...</td>\n",
       "      <td>0.240459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185310</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Chatbot: Hi Cassandra, I'm your DoorDash virtu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0   DELIVERY_ID  \\\n",
       "0             0           0  2.179857e+11   \n",
       "1             1           1  3.560231e+11   \n",
       "2             2           2  2.621826e+11   \n",
       "3             3           3  2.768723e+11   \n",
       "4             4           4  3.184242e+11   \n",
       "\n",
       "                                        CONVERSATION  IS_CNR_ABUSER  \\\n",
       "0  Chatbot: Hi Deepak, I'm your DoorDash virtual ...       0.566943   \n",
       "1  Chatbot: Hi aj, I'm your DoorDash virtual assi...       0.915407   \n",
       "2  Chatbot: Hi Luke, I'm your DoorDash virtual as...       0.099998   \n",
       "3  Chatbot: Hi Colin, I'm your DoorDash virtual a...       0.014588   \n",
       "4  Chatbot: Hi Cassandra, I'm your DoorDash virtu...       0.240459   \n",
       "\n",
       "   Parsed_AC  ORDER_SUBTOTAL  IS_VIP_CUSTOMER  ISSUE_COUNT_LAST_10_ORDERS  \\\n",
       "0        0.0           33.98              0.0                         0.0   \n",
       "1        0.0            0.00              0.0                         0.0   \n",
       "2        0.0           39.00              0.0                         0.0   \n",
       "3        0.0           15.16              0.0                         1.0   \n",
       "4        0.0           28.00              0.0                         0.0   \n",
       "\n",
       "   ISSUE_COUNT_LAST_10_DAYS  PREDICTED_ESCALATION_PROB  SH_CNR  \\\n",
       "0                       1.0                   0.102361   16.88   \n",
       "1                       4.0                   0.008399   -1.00   \n",
       "2                      15.0                   0.349462   -1.00   \n",
       "3                       1.0                   0.198509   -1.00   \n",
       "4                       0.0                   0.185310   -1.00   \n",
       "\n",
       "   CONVERSATION_HUMAN_AGENT  \\\n",
       "0                         1   \n",
       "1                         1   \n",
       "2                         1   \n",
       "3                         1   \n",
       "4                         1   \n",
       "\n",
       "                                     CONVERSATION_CB  Extracted_AC  Final_AC  \n",
       "0  Chatbot: Hi Deepak, I'm your DoorDash virtual ...           0.0       0.0  \n",
       "1  Chatbot: Hi aj, I'm your DoorDash virtual assi...           0.0       0.0  \n",
       "2  Chatbot: Hi Luke, I'm your DoorDash virtual as...           0.0       0.0  \n",
       "3  Chatbot: Hi Colin, I'm your DoorDash virtual a...           0.0       0.0  \n",
       "4  Chatbot: Hi Cassandra, I'm your DoorDash virtu...           0.0       0.0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf17d22",
   "metadata": {},
   "source": [
    "# AC Credits by Human Agents (Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "042fdaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Delivery IDs escalated to Human Agentsd and Received Apology Credits from Human Agents : 2859\n",
      "Total Apology Credits Given Out by Human Agents : $36471.16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result = dataset_final[(dataset_final['PREDICTED_ESCALATION_PROB'] >= 0.5) & (dataset_final['IS_CNR_ABUSER'] < 0.5) & (dataset_final['Final_AC'] > 0)]['DELIVERY_ID'].nunique()\n",
    "\n",
    "print(f'Number of Unique Delivery IDs escalated to Human Agentsd and Received Apology Credits from Human Agents : {result}')\n",
    "\n",
    "print(f'Total Apology Credits Given Out by Human Agents : ${dataset_final[(dataset_final['PREDICTED_ESCALATION_PROB'] >= 0.5) & (dataset_final['IS_CNR_ABUSER'] < 0.5) & (dataset_final['Final_AC'] > 0)]['Final_AC'].sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d91f81",
   "metadata": {},
   "source": [
    "# MTO Calculation : Historically\n",
    " - MTO : Manual TakeOver, Using CONVERSATION as indicator, find those cases where the case was escalated to Human Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "21fe2bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Delivery IDs escalated to Human Agents : 12278\n",
      "Percentage of Unique Delivery IDs with escalated to Human Agents : 0.008682916549095818\n"
     ]
    }
   ],
   "source": [
    "dataset_escalated = dataset_final[(dataset_final['PREDICTED_ESCALATION_PROB'] >= 0.5) & (dataset_final['IS_CNR_ABUSER'] < 0.5)]\n",
    "print(f'Number of Unique Delivery IDs escalated to Human Agents : {dataset_escalated.shape[0]}')\n",
    "print(f'Percentage of Unique Delivery IDs with escalated to Human Agents : {dataset_escalated.shape[0] / dataset_final.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final_escalated_cases = pd.read_csv('/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/processed_dataset/dataset_final_escalated_cases.csv').iloc[:,2:]\n",
    "extracted_ac = dataset_final[dataset_final['DELIVERY_ID'].isin(dataset_final_escalated_cases['DELIVERY_ID'])][['DELIVERY_ID','Final_AC']]\n",
    "dataset_final_escalated_cases = pd.merge(dataset_final_escalated_cases,extracted_ac,on='DELIVERY_ID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91488b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_final_escalated_cases.to_csv('/Users/shekhar.tanwar/Documents/Projects/NegotiatonAgent/dataset/processed_dataset/dataset_final_escalated_cases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cff4a21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DELIVERY_ID</th>\n",
       "      <th>CONVERSATION</th>\n",
       "      <th>IS_CNR_ABUSER</th>\n",
       "      <th>Parsed_AC</th>\n",
       "      <th>ORDER_SUBTOTAL</th>\n",
       "      <th>IS_VIP_CUSTOMER</th>\n",
       "      <th>ISSUE_COUNT_LAST_10_ORDERS</th>\n",
       "      <th>ISSUE_COUNT_LAST_10_DAYS</th>\n",
       "      <th>PREDICTED_ESCALATION_PROB</th>\n",
       "      <th>SH_CNR</th>\n",
       "      <th>CONVERSATION_HUMAN_AGENT</th>\n",
       "      <th>CONVERSATION_CB</th>\n",
       "      <th>Final_AC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.274258e+11</td>\n",
       "      <td>Chatbot: Hi Kaley, I'm your DoorDash virtual a...</td>\n",
       "      <td>0.125763</td>\n",
       "      <td>30.0</td>\n",
       "      <td>52.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.510681</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Chatbot: Hi Kaley, I'm your DoorDash virtual a...</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.367102e+11</td>\n",
       "      <td>Chatbot: Hi Erin, thanks for being one of our ...</td>\n",
       "      <td>0.028421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.539183</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Chatbot: Hi Erin, thanks for being one of our ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.321655e+11</td>\n",
       "      <td>Chatbot: Hi Dana, I'm your DoorDash virtual as...</td>\n",
       "      <td>0.210172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.620139</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Chatbot: Hi Dana, I'm your DoorDash virtual as...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.239209e+11</td>\n",
       "      <td>Chatbot: Hi Abigail, I'm your DoorDash virtual...</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.563792</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Chatbot: Hi Abigail, I'm your DoorDash virtual...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.255888e+11</td>\n",
       "      <td>Chatbot: Hi James, I'm your DoorDash virtual a...</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.504190</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Chatbot: Hi James, I'm your DoorDash virtual a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DELIVERY_ID                                       CONVERSATION  \\\n",
       "0  3.274258e+11  Chatbot: Hi Kaley, I'm your DoorDash virtual a...   \n",
       "1  3.367102e+11  Chatbot: Hi Erin, thanks for being one of our ...   \n",
       "2  2.321655e+11  Chatbot: Hi Dana, I'm your DoorDash virtual as...   \n",
       "3  2.239209e+11  Chatbot: Hi Abigail, I'm your DoorDash virtual...   \n",
       "4  2.255888e+11  Chatbot: Hi James, I'm your DoorDash virtual a...   \n",
       "\n",
       "   IS_CNR_ABUSER  Parsed_AC  ORDER_SUBTOTAL  IS_VIP_CUSTOMER  \\\n",
       "0       0.125763       30.0           52.22              1.0   \n",
       "1       0.028421        0.0           37.56              0.0   \n",
       "2       0.210172        0.0            6.70              1.0   \n",
       "3       0.005853        0.0           25.98              1.0   \n",
       "4       0.008150        0.0           33.25              1.0   \n",
       "\n",
       "   ISSUE_COUNT_LAST_10_ORDERS  ISSUE_COUNT_LAST_10_DAYS  \\\n",
       "0                         4.0                      35.0   \n",
       "1                         1.0                      12.0   \n",
       "2                         2.0                      27.0   \n",
       "3                         0.0                       4.0   \n",
       "4                         0.0                      21.0   \n",
       "\n",
       "   PREDICTED_ESCALATION_PROB  SH_CNR  CONVERSATION_HUMAN_AGENT  \\\n",
       "0                   0.510681    -1.0                         1   \n",
       "1                   0.539183    -1.0                         1   \n",
       "2                   0.620139    -1.0                         1   \n",
       "3                   0.563792    -1.0                         1   \n",
       "4                   0.504190    -1.0                         1   \n",
       "\n",
       "                                     CONVERSATION_CB  Final_AC  \n",
       "0  Chatbot: Hi Kaley, I'm your DoorDash virtual a...      30.0  \n",
       "1  Chatbot: Hi Erin, thanks for being one of our ...       0.0  \n",
       "2  Chatbot: Hi Dana, I'm your DoorDash virtual as...       0.0  \n",
       "3  Chatbot: Hi Abigail, I'm your DoorDash virtual...      20.0  \n",
       "4  Chatbot: Hi James, I'm your DoorDash virtual a...       0.0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_final_escalated_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228de89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc81f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
